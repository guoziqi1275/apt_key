{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 3: Datasets\n",
    "In this notebook, we'll go over how to implement different measures to your AI model using datasets. We are specifically aiming to adapt measures from cognitive psychology to adminsiter via the API. This requires us to make each item in the measure (text or text/image) pair callable in our API function through a dataset\n",
    "\n",
    "**Make sure to download the necessary zip file and upload it to JupyterLab before running this script**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# make sure nb2_files.zip exists\n",
    "if not os.path.exists('nb3_files.zip'):\n",
    "    print('nb3_files.zip not found. Please make sure it exists in the current directory.')\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First unzip tutorial contents\n",
    "import shutil\n",
    "shutil.unpack_archive('nb3_files.zip', 'nb3_files')\n",
    "\n",
    "notebook_files_path = 'nb3_files/nb3_files/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Text-only vs Text-Image pair dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the task you select, it might make more sense to use text-only data or text/image pair data.\n",
    "\n",
    "Text-only data is preferable if your task is evaluating the linguistic abilities of AI systems. For example, maybe your idea of intelligence is highly influenced by someone's ability to do verbal reasoning. In that case, you may want to find certain reasoning puzzles from cognitive psychology to administer through the API.\n",
    "\n",
    "Text/Image data is preferable if your task evaluates both linguistic and visual abilities of AI systems. For example, spatial reasoning tasks require subjects to look at images, videos, some visual stimuli to reason about spatial qualities in the scene."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 JSON files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make all the course projects as accessible as possible, we will provide code that allows you to call the API and evaluate a dataset.\n",
    "\n",
    "Since this is an established function, all your datasets need to be in a specific format. This format will require you to use a special kind of text file called a JSON file. This is a specifically convenient format because it allows for structured, human-readable, text-storing and can be loaded into python directly to a dataframe for analysis!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSON files are similar to dictionaries (the mapping object type) we learned in notebook 1. They contain key-value pairs:\n",
    "\n",
    "```{JSON}\n",
    "[\n",
    "    {\n",
    "        \"id\": \"250\",\n",
    "        \"image\": \"000000000370.jpg\",\n",
    "        \"conversations\": [\n",
    "            {\n",
    "                \"from\": \"human\",\n",
    "                \"value\": \"<image>\\nIs the broccoli to the left or right from person's perspectice?\"\n",
    "            },\n",
    "            {\n",
    "                \"from\": \"gpt\",\n",
    "                \"value\": \"The broccoli is to the left from the person's perspective\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "This is an example of some fine-tuning data:\n",
    "- id is a unique identifier for the item\n",
    "- image is the path to the image of reference\n",
    "- conversations is the actual data used during fine-tuning where \"from\":\"human\" is the prompt and \"from\":\"gpt\" is the ideal response\n",
    "- this is one item of many that would all be stored in a similar format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our datasets will look somewhat similar to this:\n",
    "\n",
    "```{JSON}\n",
    "[\n",
    "    {\n",
    "        \"id\": \"unique_id\",\n",
    "        \"image\": \"image_path\" or None (for text-only),\n",
    "        \"prompt\": \"dataset_text\"\n",
    "    },\n",
    "    ...\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make things easy, let's define a function that formats a json item\n",
    "def format_json_item(id, image, prompt):\n",
    "    return {\n",
    "        \"id\": id,\n",
    "        \"image\": image,\n",
    "        \"prompt\": prompt\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Example: Making a text-only dataset\n",
    "\n",
    "Here we use a Syllogistic Reasoning Task to make a text-only dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the items:\n",
    "\n",
    "Valid Reasoning (Logically Correct)\n",
    "\n",
    "1. All fruits have seeds. An apple is a fruit. → Therefore, an apple has seeds. (Valid)\n",
    "\n",
    "2. All squares are rectangles. All rectangles have four sides. → Therefore, all squares have four sides. (Valid)\n",
    "\n",
    "3. No reptiles are warm-blooded. All snakes are reptiles. → Therefore, no snakes are warm-blooded. (Valid)\n",
    "\n",
    "4. All birds lay eggs. Penguins are birds. → Therefore, penguins lay eggs. (Valid)\n",
    "\n",
    "5. Some humans are musicians. All musicians can read music. → Therefore, some humans can read music. (Valid)\n",
    "\n",
    "Invalid Reasoning (Logical Fallacy)\n",
    "\n",
    "1. All dogs are animals. All cats are animals. → Therefore, all dogs are cats. (Invalid – Illicit Conversion Fallacy)\n",
    "\n",
    "2. Some tall people are basketball players. Michael is tall. → Therefore, Michael is a basketball player. (Invalid – Incorrect Generalization)\n",
    "\n",
    "3. No insects are mammals. A spider is not an insect. → Therefore, a spider is a mammal. (Invalid – Incorrect Negative Inference)\n",
    "\n",
    "4. All fish live in water. Dolphins live in water. → Therefore, dolphins are fish. (Invalid – Category Mistake)\n",
    "\n",
    "5. All roses are flowers. Some flowers are red. → Therefore, all roses are red. (Invalid – False Distribution Fallacy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting Instructions\n",
    "\n",
    "For this task, we will use the same instructions for all items:\n",
    "\n",
    "Each question contains two premises and a conclusion. Your task is to determine whether the conclusion logically follows from the premises. If the conclusion is logically valid, select \"Valid\". If the conclusion does not logically follow, select \"Invalid\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \\n is a newline character\n",
    "instructions = \"Each question contains two premises and a conclusion. Your task is to determine whether the conclusion logically follows from the premises.\\nIf the conclusion is logically valid, select 'Valid'.\\nIf the conclusion does not logically follow, select 'Invalid'.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each question contains two premises and a conclusion. Your task is to determine whether the conclusion logically follows from the premises.\n",
      "If the conclusion is logically valid, select 'Valid'.\n",
      "If the conclusion does not logically follow, select 'Invalid'.\n"
     ]
    }
   ],
   "source": [
    "print(instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Premise 1: All fruits have seeds.\n",
      "Premise 2: An apple is a fruit.\n",
      "Conclusion: Therefore, an apple has seeds.\n"
     ]
    }
   ],
   "source": [
    "item_1 =  \"Premise 1: All fruits have seeds.\\nPremise 2: An apple is a fruit.\\nConclusion: Therefore, an apple has seeds.\"\n",
    "print(item_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rest of the items\n",
    "item_2 =  \"Premise 1: All squares are rectangles.\\nPremise 2: All rectangles have four sides.\\nConclusion: Therefore, all squares have four sides.\"\n",
    "item_3 =  \"Premise 1: No reptiles are warm-blooded.\\nPremise 2: All snakes are reptiles.\\nConclusion: Therefore, no snakes are warm-blooded.\"\n",
    "item_4 =  \"Premise 1: All birds lay eggs.\\nPremise 2: Penguins are birds.\\nConclusion: Therefore, penguins lay eggs.\"\n",
    "item_5 =  \"Premise 1: Some humans are musicians.\\nPremise 2: All musicians can read music.\\nConclusion: Therefore, some humans can read music.\"\n",
    "item_6 = \"Premise 1: All dogs are animals.\\nPremise 2: All cats are animals.\\nConclusion: Therefore, all dogs are cats.\"\n",
    "item_7 = \"Premise 1: Some tall people are basketball players.\\nPremise 2: Michael is tall.\\nConclusion: Therefore, Michael is a basketball player.\"\n",
    "item_8 = \"Premise 1: No insects are mammals.\\nPremise 2: A spider is not an insect.\\nConclusion: Therefore, a spider is a mammal.\"\n",
    "item_9 = \"Premise 1: All fish live in water.\\nPremise 2: Dolphins live in water.\\nConclusion: Therefore, dolphins are fish.\"\n",
    "item_10 = \"Premise 1: All roses are flowers.\\nPremise 2: Some flowers are red.\\nConclusion: Therefore, all roses are red.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_items = [item_1, item_2, item_3, item_4, item_5, item_6, item_7, item_8, item_9, item_10]\n",
    "\n",
    "json_items = []\n",
    "\n",
    "# lets loop through each item and format it as a json item\n",
    "for i in range(len(all_items)):\n",
    "    # id will be item number with leading zeros so that each id is two digits\n",
    "    id = f\"{i:02d}\"\n",
    "    image = None  # no image for this task\n",
    "    # our actual prompt for the model with be the instruction followed by the item\n",
    "    prompt = instructions + \"\\n\" + all_items[i]\n",
    "\n",
    "    # now add this formatted item to our json_items list\n",
    "    json_items.append(format_json_item(id, image, prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '00',\n",
       "  'image': None,\n",
       "  'prompt': \"Each question contains two premises and a conclusion. Your task is to determine whether the conclusion logically follows from the premises.\\nIf the conclusion is logically valid, select 'Valid'.\\nIf the conclusion does not logically follow, select 'Invalid'.\\nPremise 1: All fruits have seeds.\\nPremise 2: An apple is a fruit.\\nConclusion: Therefore, an apple has seeds.\"},\n",
       " {'id': '01',\n",
       "  'image': None,\n",
       "  'prompt': \"Each question contains two premises and a conclusion. Your task is to determine whether the conclusion logically follows from the premises.\\nIf the conclusion is logically valid, select 'Valid'.\\nIf the conclusion does not logically follow, select 'Invalid'.\\nPremise 1: All squares are rectangles.\\nPremise 2: All rectangles have four sides.\\nConclusion: Therefore, all squares have four sides.\"},\n",
       " {'id': '02',\n",
       "  'image': None,\n",
       "  'prompt': \"Each question contains two premises and a conclusion. Your task is to determine whether the conclusion logically follows from the premises.\\nIf the conclusion is logically valid, select 'Valid'.\\nIf the conclusion does not logically follow, select 'Invalid'.\\nPremise 1: No reptiles are warm-blooded.\\nPremise 2: All snakes are reptiles.\\nConclusion: Therefore, no snakes are warm-blooded.\"}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's check that the first three items are formatted correctly\n",
    "json_items[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 10 items to nb3_textonly_dataset.json\n"
     ]
    }
   ],
   "source": [
    "# Looks good! Let's save this as a json file\n",
    "output_path = 'nb3_textonly_dataset.json'\n",
    "\n",
    "import json\n",
    "with open(output_path, 'w') as f: # open file in write mode\n",
    "    # indent=4 is not necessary but makes it more readable for us\n",
    "    json.dump(json_items, f, indent=4) # write our list of json items to file\n",
    "    print(f\"Saved {len(json_items)} items to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Example: making an text/image pair dataset\n",
    "\n",
    "Here we'll use the RMET data to make a dataset. We already have the RMET materials available locally in the rmet_materials folder. We'll use this to build our dataset instead of manually entering every item like before!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choose which word best describes what the person in the picture is thinking or feeling based on their eyes alone.\n",
      "Even if you feel like you cannot tell based on their eyes alone, please select the best word.\n",
      "You may feel that more than one word is applicable, but please choose just one word, the word which you consider to be most suitable.\n",
      "Your 4 choices are: \n"
     ]
    }
   ],
   "source": [
    "instructions = \"Choose which word best describes what the person in the picture is thinking or feeling based on their eyes alone.\\nEven if you feel like you cannot tell based on their eyes alone, please select the best word.\\nYou may feel that more than one word is applicable, but please choose just one word, the word which you consider to be most suitable.\\nYour 4 choices are: \"\n",
    "print(instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['playful comforting irritated bored',\n",
       " 'terrified upset arrogant annoyed',\n",
       " 'joking flustered desire convinced']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(f'{notebook_files_path}word_choices.txt', \"r\") as f:\n",
    "    word_choices = f.readlines()\n",
    "word_choices = [x.strip() for x in word_choices]\n",
    "\n",
    "word_choices[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# all the images I want to use are in my github repo at this location: bridgetleonard2/Eyes-Mind-Model/main/task_materials/regular\n",
    "# get all image files in the images directory\n",
    "images = os.listdir(f'{notebook_files_path}images')\n",
    "# sort images so names are ordered\n",
    "images.sort()\n",
    "images[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*If you are creating a dataset using data you have locally, make sure things are in the **order** that you want. You don't want to create wrong pairs of data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_items = [] # clear out this list\n",
    "\n",
    "for i in range(len(images)):\n",
    "    # id will be item number with leading zeros so that each id is two digits\n",
    "    id = f\"{i:02d}\"\n",
    "    image = images[i]  # image file name\n",
    "    # our actual prompt for the model with be the instruction followed by the word choices\n",
    "    item_words = word_choices[i]\n",
    "    prompt = instructions + item_words\n",
    "\n",
    "    # now add this formatted item to our json_items list\n",
    "    json_items.append(format_json_item(id, image, prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '00',\n",
       "  'image': 'https://raw.githubusercontent.com/bridgetleonard2/Eyes-Mind-Model/main/task_materials/regular/01-playful-comforting-irritated-bored-300x175.jpg',\n",
       "  'prompt': 'Choose which word best describes what the person in the picture is thinking or feeling based on their eyes alone.\\nEven if you feel like you cannot tell based on their eyes alone, please select the best word.\\nYou may feel that more than one word is applicable, but please choose just one word, the word which you consider to be most suitable.\\nYour 4 choices are: playful comforting irritated bored'},\n",
       " {'id': '01',\n",
       "  'image': 'https://raw.githubusercontent.com/bridgetleonard2/Eyes-Mind-Model/main/task_materials/regular/02-terrified-upset-arrogant-annoyed-300x175.jpg',\n",
       "  'prompt': 'Choose which word best describes what the person in the picture is thinking or feeling based on their eyes alone.\\nEven if you feel like you cannot tell based on their eyes alone, please select the best word.\\nYou may feel that more than one word is applicable, but please choose just one word, the word which you consider to be most suitable.\\nYour 4 choices are: terrified upset arrogant annoyed'},\n",
       " {'id': '02',\n",
       "  'image': 'https://raw.githubusercontent.com/bridgetleonard2/Eyes-Mind-Model/main/task_materials/regular/03-joking-flustered-desire-convinced-300x175.jpg',\n",
       "  'prompt': 'Choose which word best describes what the person in the picture is thinking or feeling based on their eyes alone.\\nEven if you feel like you cannot tell based on their eyes alone, please select the best word.\\nYou may feel that more than one word is applicable, but please choose just one word, the word which you consider to be most suitable.\\nYour 4 choices are: joking flustered desire convinced'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_items[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 36 items to nb3_imagetext_dataset.json\n"
     ]
    }
   ],
   "source": [
    "# Looks good! Let's save this as a json file\n",
    "output_path = 'nb3_imagetext_dataset.json'\n",
    "\n",
    "import json\n",
    "with open(output_path, 'w') as f: # open file in write mode\n",
    "    # indent=4 is not necessary but makes it more readable for us\n",
    "    json.dump(json_items, f, indent=4) # write our list of json items to file\n",
    "    print(f\"Saved {len(json_items)} items to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
