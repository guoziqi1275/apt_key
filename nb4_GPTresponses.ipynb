{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 4: GPT Responses\n",
    "\n",
    "This notebook will go over 3 parts of analysis:\n",
    "1. Running the dataset through the API\n",
    "2. Cleaning the response data\n",
    "\n",
    "**Make sure to download the necessary zip file and upload it to JupyterLab before running this script**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# make sure nb2_files.zip exists\n",
    "if not os.path.exists('nb4_files.zip'):\n",
    "    print('nb4_files.zip not found. Please make sure it exists in the current directory.')\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First unzip tutorial contents\n",
    "import shutil\n",
    "shutil.unpack_archive('nb4_files.zip', 'nb4_files')\n",
    "\n",
    "notebook_files_path = 'nb4_files/nb4_files/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Running your dataset through the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nb4_files.nb4_files.gpt_api import process_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the function\n",
    "process_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start with the text-only task\n",
    "dataset_path = f\"{notebook_files_path}nb3_textonly_dataset.json\"\n",
    "API_KEY = \"\"\n",
    "output_path = \"nb4_textonly_responses.json\"\n",
    "num_attempts = 1\n",
    "\n",
    "textonly_responses = process_dataset(dataset_path, API_KEY, output_path, num_attempts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's try the image-text pair task\n",
    "dataset_path = f\"{notebook_files_path}nb3_imagetext_dataset.json\"\n",
    "output_path = \"nb4_imagetext_responses.json\"\n",
    "num_attempts = 5\n",
    "image_dir = f\"{notebook_files_path}images\"\n",
    "\n",
    "imagetextpair_responses = process_dataset(dataset_path, API_KEY, output_path, num_attempts, image_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Text-only data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Cleaning text-only data\n",
    "\n",
    "Now we want to clean the output responses so we can measure whether they are correct or incorrect. We can do this manually by looking at the json outputs or using code\n",
    "\n",
    "For the text only data we prompted the model to respond whether the conclusion was valid or invalid. Let's first store these in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '00',\n",
       "  'attempt': 0,\n",
       "  'prompt': \"Each question contains two premises and a conclusion. Your task is to determine whether the conclusion logically follows from the premises.\\nIf the conclusion is logically valid, select 'Valid'.\\nIf the conclusion does not logically follow, select 'Invalid'.\\nPremise 1: All fruits have seeds.\\nPremise 2: An apple is a fruit.\\nConclusion: Therefore, an apple has seeds.\",\n",
       "  'response': 'Valid'},\n",
       " {'id': '01',\n",
       "  'attempt': 0,\n",
       "  'prompt': \"Each question contains two premises and a conclusion. Your task is to determine whether the conclusion logically follows from the premises.\\nIf the conclusion is logically valid, select 'Valid'.\\nIf the conclusion does not logically follow, select 'Invalid'.\\nPremise 1: All squares are rectangles.\\nPremise 2: All rectangles have four sides.\\nConclusion: Therefore, all squares have four sides.\",\n",
       "  'response': 'Valid.'},\n",
       " {'id': '02',\n",
       "  'attempt': 0,\n",
       "  'prompt': \"Each question contains two premises and a conclusion. Your task is to determine whether the conclusion logically follows from the premises.\\nIf the conclusion is logically valid, select 'Valid'.\\nIf the conclusion does not logically follow, select 'Invalid'.\\nPremise 1: No reptiles are warm-blooded.\\nPremise 2: All snakes are reptiles.\\nConclusion: Therefore, no snakes are warm-blooded.\",\n",
       "  'response': 'Valid'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textonly_responses[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>attempt</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00</td>\n",
       "      <td>0</td>\n",
       "      <td>Each question contains two premises and a conc...</td>\n",
       "      <td>Valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01</td>\n",
       "      <td>0</td>\n",
       "      <td>Each question contains two premises and a conc...</td>\n",
       "      <td>Valid.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02</td>\n",
       "      <td>0</td>\n",
       "      <td>Each question contains two premises and a conc...</td>\n",
       "      <td>Valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03</td>\n",
       "      <td>0</td>\n",
       "      <td>Each question contains two premises and a conc...</td>\n",
       "      <td>Valid.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04</td>\n",
       "      <td>0</td>\n",
       "      <td>Each question contains two premises and a conc...</td>\n",
       "      <td>Valid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  attempt                                             prompt response\n",
       "0  00        0  Each question contains two premises and a conc...    Valid\n",
       "1  01        0  Each question contains two premises and a conc...   Valid.\n",
       "2  02        0  Each question contains two premises and a conc...    Valid\n",
       "3  03        0  Each question contains two premises and a conc...   Valid.\n",
       "4  04        0  Each question contains two premises and a conc...    Valid"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textonly_df = pd.DataFrame(textonly_responses)\n",
    "textonly_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From visual inspection, it looks like sometimes the response contains a period at the end and sometimes it doesn't. Let's remove periods if they exist and also make the response all lower-case to make our analysis easier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>attempt</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00</td>\n",
       "      <td>0</td>\n",
       "      <td>Each question contains two premises and a conc...</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01</td>\n",
       "      <td>0</td>\n",
       "      <td>Each question contains two premises and a conc...</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02</td>\n",
       "      <td>0</td>\n",
       "      <td>Each question contains two premises and a conc...</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03</td>\n",
       "      <td>0</td>\n",
       "      <td>Each question contains two premises and a conc...</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04</td>\n",
       "      <td>0</td>\n",
       "      <td>Each question contains two premises and a conc...</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  attempt                                             prompt response\n",
       "0  00        0  Each question contains two premises and a conc...    valid\n",
       "1  01        0  Each question contains two premises and a conc...    valid\n",
       "2  02        0  Each question contains two premises and a conc...    valid\n",
       "3  03        0  Each question contains two premises and a conc...    valid\n",
       "4  04        0  Each question contains two premises and a conc...    valid"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textonly_df['response'] = textonly_df['response'].apply(lambda x: x.replace(\".\", \"\").lower())\n",
    "textonly_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "response\n",
       "valid                                                                                                                                                                                                                                                     5\n",
       "invalid                                                                                                                                                                                                                                                   4\n",
       "invalid the conclusion does not logically follow from the premises the premises only establish that no insects are mammals and that a spider is not an insect however, this does not provide any information about whether a spider is a mammal or not    1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textonly_df['response'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "response\n",
       "valid      5\n",
       "invalid    5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looks like there's still a weird long answer so let's take only the first word of each response\n",
    "textonly_df['response'] = textonly_df['response'].apply(lambda x: x.split(\" \")[0])\n",
    "textonly_df['response'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 Text-only analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>attempt</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00</td>\n",
       "      <td>0</td>\n",
       "      <td>Each question contains two premises and a conc...</td>\n",
       "      <td>valid</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01</td>\n",
       "      <td>0</td>\n",
       "      <td>Each question contains two premises and a conc...</td>\n",
       "      <td>valid</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02</td>\n",
       "      <td>0</td>\n",
       "      <td>Each question contains two premises and a conc...</td>\n",
       "      <td>valid</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03</td>\n",
       "      <td>0</td>\n",
       "      <td>Each question contains two premises and a conc...</td>\n",
       "      <td>valid</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04</td>\n",
       "      <td>0</td>\n",
       "      <td>Each question contains two premises and a conc...</td>\n",
       "      <td>valid</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  attempt                                             prompt response  \\\n",
       "0  00        0  Each question contains two premises and a conc...    valid   \n",
       "1  01        0  Each question contains two premises and a conc...    valid   \n",
       "2  02        0  Each question contains two premises and a conc...    valid   \n",
       "3  03        0  Each question contains two premises and a conc...    valid   \n",
       "4  04        0  Each question contains two premises and a conc...    valid   \n",
       "\n",
       "  answer  \n",
       "0  valid  \n",
       "1  valid  \n",
       "2  valid  \n",
       "3  valid  \n",
       "4  valid  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's add a correct answers column\n",
    "answers = [\"valid\"] * 5 + [\"invalid\"] * 5\n",
    "textonly_df['answer'] = answers\n",
    "textonly_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>attempt</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>answer</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00</td>\n",
       "      <td>0</td>\n",
       "      <td>Each question contains two premises and a conc...</td>\n",
       "      <td>valid</td>\n",
       "      <td>valid</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01</td>\n",
       "      <td>0</td>\n",
       "      <td>Each question contains two premises and a conc...</td>\n",
       "      <td>valid</td>\n",
       "      <td>valid</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02</td>\n",
       "      <td>0</td>\n",
       "      <td>Each question contains two premises and a conc...</td>\n",
       "      <td>valid</td>\n",
       "      <td>valid</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03</td>\n",
       "      <td>0</td>\n",
       "      <td>Each question contains two premises and a conc...</td>\n",
       "      <td>valid</td>\n",
       "      <td>valid</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04</td>\n",
       "      <td>0</td>\n",
       "      <td>Each question contains two premises and a conc...</td>\n",
       "      <td>valid</td>\n",
       "      <td>valid</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  attempt                                             prompt response  \\\n",
       "0  00        0  Each question contains two premises and a conc...    valid   \n",
       "1  01        0  Each question contains two premises and a conc...    valid   \n",
       "2  02        0  Each question contains two premises and a conc...    valid   \n",
       "3  03        0  Each question contains two premises and a conc...    valid   \n",
       "4  04        0  Each question contains two premises and a conc...    valid   \n",
       "\n",
       "  answer  correct  \n",
       "0  valid     True  \n",
       "1  valid     True  \n",
       "2  valid     True  \n",
       "3  valid     True  \n",
       "4  valid     True  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# finally let's make a corrrect column if the response is the same as the answer\n",
    "textonly_df['correct'] = textonly_df['response'] == textonly_df['answer']\n",
    "textonly_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = textonly_df['correct'].sum()/len(textonly_df)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Image-text pair data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"nb4_imagetext_responses.json\", \"r\") as f:\n",
    "    imagetextpair_responses = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '00',\n",
       "  'attempt': 0,\n",
       "  'prompt': 'Choose which word best describes what the person in the picture is thinking or feeling based on their eyes alone.\\nEven if you feel like you cannot tell based on their eyes alone, please select the best word.\\nYou may feel that more than one word is applicable, but please choose just one word, the word which you consider to be most suitable.\\nYour 4 choices are: playful comforting irritated bored',\n",
       "  'response': \"I'm unable to determine what the person is thinking or feeling based on their eyes alone.\"},\n",
       " {'id': '00',\n",
       "  'attempt': 1,\n",
       "  'prompt': 'Choose which word best describes what the person in the picture is thinking or feeling based on their eyes alone.\\nEven if you feel like you cannot tell based on their eyes alone, please select the best word.\\nYou may feel that more than one word is applicable, but please choose just one word, the word which you consider to be most suitable.\\nYour 4 choices are: playful comforting irritated bored',\n",
       "  'response': 'I don\\'t know who this person is, but based on the eyes alone, the best word to describe what they might be feeling is \"playful.\"'},\n",
       " {'id': '00',\n",
       "  'attempt': 2,\n",
       "  'prompt': 'Choose which word best describes what the person in the picture is thinking or feeling based on their eyes alone.\\nEven if you feel like you cannot tell based on their eyes alone, please select the best word.\\nYou may feel that more than one word is applicable, but please choose just one word, the word which you consider to be most suitable.\\nYour 4 choices are: playful comforting irritated bored',\n",
       "  'response': 'I don\\'t know who the person is, but based on the eyes alone, the best word to describe what they might be feeling is \"playful.\"'}]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagetextpair_responses[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These responses look a little trickier to clean...\n",
    "\n",
    "Maybe we should clean these manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_imagetextpair_responses = imagetextpair_responses.copy()\n",
    "\n",
    "for i, item in enumerate(cleaned_imagetextpair_responses):\n",
    "    response = item['response']\n",
    "    if len(response.split(\" \")) == 1:\n",
    "        clean_response = response.strip().lower().replace(\".\", \"\")\n",
    "    else:\n",
    "        # find the word in \"\" and take that\n",
    "        quote_match = re.search(r'\"([^\"]*)\"', response)\n",
    "        if quote_match:\n",
    "            clean_response = quote_match.group(1).strip().lower().replace(\".\", \"\")\n",
    "        else:\n",
    "            clean_response = None\n",
    "    cleaned_imagetextpair_responses[i]['response'] = clean_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>attempt</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00</td>\n",
       "      <td>0</td>\n",
       "      <td>Choose which word best describes what the pers...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00</td>\n",
       "      <td>1</td>\n",
       "      <td>Choose which word best describes what the pers...</td>\n",
       "      <td>playful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00</td>\n",
       "      <td>2</td>\n",
       "      <td>Choose which word best describes what the pers...</td>\n",
       "      <td>playful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00</td>\n",
       "      <td>3</td>\n",
       "      <td>Choose which word best describes what the pers...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00</td>\n",
       "      <td>4</td>\n",
       "      <td>Choose which word best describes what the pers...</td>\n",
       "      <td>playful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  attempt                                             prompt response\n",
       "0  00        0  Choose which word best describes what the pers...     None\n",
       "1  00        1  Choose which word best describes what the pers...  playful\n",
       "2  00        2  Choose which word best describes what the pers...  playful\n",
       "3  00        3  Choose which word best describes what the pers...     None\n",
       "4  00        4  Choose which word best describes what the pers...  playful"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagetext_df = pd.DataFrame(cleaned_imagetextpair_responses)\n",
    "imagetext_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagetext_df['response'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many are invalid?\n",
    "num_invalid = imagetext_df['response'].isnull().sum()\n",
    "num_invalid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['playful', 'upset', 'desire']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(f\"{notebook_files_path}answers.txt\", \"r\") as f:\n",
    "    answers = f.readlines()\n",
    "answers = [x.strip() for x in answers]\n",
    "answers[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00</td>\n",
       "      <td>playful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01</td>\n",
       "      <td>upset</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02</td>\n",
       "      <td>desire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>03</td>\n",
       "      <td>insisting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>04</td>\n",
       "      <td>worried</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     answer\n",
       "0  00    playful\n",
       "1  01      upset\n",
       "2  02     desire\n",
       "3  03  insisting\n",
       "4  04    worried"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id = [f\"{i:02d}\" for i in range(0, 36)]\n",
    "answers_id = dict(zip(id, answers))\n",
    "answers_id = pd.DataFrame(answers_id.items(), columns=['id', 'answer'])\n",
    "answers_id.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>attempt</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00</td>\n",
       "      <td>0</td>\n",
       "      <td>Choose which word best describes what the pers...</td>\n",
       "      <td>None</td>\n",
       "      <td>playful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00</td>\n",
       "      <td>1</td>\n",
       "      <td>Choose which word best describes what the pers...</td>\n",
       "      <td>playful</td>\n",
       "      <td>playful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00</td>\n",
       "      <td>2</td>\n",
       "      <td>Choose which word best describes what the pers...</td>\n",
       "      <td>playful</td>\n",
       "      <td>playful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00</td>\n",
       "      <td>3</td>\n",
       "      <td>Choose which word best describes what the pers...</td>\n",
       "      <td>None</td>\n",
       "      <td>playful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00</td>\n",
       "      <td>4</td>\n",
       "      <td>Choose which word best describes what the pers...</td>\n",
       "      <td>playful</td>\n",
       "      <td>playful</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  attempt                                             prompt response  \\\n",
       "0  00        0  Choose which word best describes what the pers...     None   \n",
       "1  00        1  Choose which word best describes what the pers...  playful   \n",
       "2  00        2  Choose which word best describes what the pers...  playful   \n",
       "3  00        3  Choose which word best describes what the pers...     None   \n",
       "4  00        4  Choose which word best describes what the pers...  playful   \n",
       "\n",
       "    answer  \n",
       "0  playful  \n",
       "1  playful  \n",
       "2  playful  \n",
       "3  playful  \n",
       "4  playful  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagetext_df = imagetext_df.merge(answers_id, on='id')\n",
    "imagetext_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>attempt</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response</th>\n",
       "      <th>answer</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00</td>\n",
       "      <td>0</td>\n",
       "      <td>Choose which word best describes what the pers...</td>\n",
       "      <td>None</td>\n",
       "      <td>playful</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00</td>\n",
       "      <td>1</td>\n",
       "      <td>Choose which word best describes what the pers...</td>\n",
       "      <td>playful</td>\n",
       "      <td>playful</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00</td>\n",
       "      <td>2</td>\n",
       "      <td>Choose which word best describes what the pers...</td>\n",
       "      <td>playful</td>\n",
       "      <td>playful</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00</td>\n",
       "      <td>3</td>\n",
       "      <td>Choose which word best describes what the pers...</td>\n",
       "      <td>None</td>\n",
       "      <td>playful</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00</td>\n",
       "      <td>4</td>\n",
       "      <td>Choose which word best describes what the pers...</td>\n",
       "      <td>playful</td>\n",
       "      <td>playful</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  attempt                                             prompt response  \\\n",
       "0  00        0  Choose which word best describes what the pers...     None   \n",
       "1  00        1  Choose which word best describes what the pers...  playful   \n",
       "2  00        2  Choose which word best describes what the pers...  playful   \n",
       "3  00        3  Choose which word best describes what the pers...     None   \n",
       "4  00        4  Choose which word best describes what the pers...  playful   \n",
       "\n",
       "    answer  correct  \n",
       "0  playful    False  \n",
       "1  playful     True  \n",
       "2  playful     True  \n",
       "3  playful    False  \n",
       "4  playful     True  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagetext_df['correct'] = imagetext_df['response'] == imagetext_df['answer']\n",
    "imagetext_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item 1 Accuracy: 0.6\n",
      "Item 2 Accuracy: 0.6\n",
      "Item 3 Accuracy: 1.0\n",
      "Item 4 Accuracy: 0.2\n",
      "Item 5 Accuracy: 1.0\n",
      "Item 6 Accuracy: 0.2\n",
      "Item 7 Accuracy: 1.0\n",
      "Item 8 Accuracy: 0.8\n",
      "Item 9 Accuracy: 0.8\n",
      "Item 10 Accuracy: 0.0\n",
      "Item 11 Accuracy: 0.8\n",
      "Item 12 Accuracy: 0.8\n",
      "Item 13 Accuracy: 0.6\n",
      "Item 14 Accuracy: 0.6\n",
      "Item 15 Accuracy: 1.0\n",
      "Item 16 Accuracy: 1.0\n",
      "Item 17 Accuracy: 0.2\n",
      "Item 18 Accuracy: 0.2\n",
      "Item 19 Accuracy: 0.0\n",
      "Item 20 Accuracy: 0.0\n",
      "Item 21 Accuracy: 0.0\n",
      "Item 22 Accuracy: 0.0\n",
      "Item 23 Accuracy: 0.0\n",
      "Item 24 Accuracy: 0.0\n",
      "Item 25 Accuracy: 0.0\n",
      "Item 26 Accuracy: 0.0\n",
      "Item 27 Accuracy: 0.2\n",
      "Item 28 Accuracy: 0.0\n",
      "Item 29 Accuracy: 1.0\n",
      "Item 30 Accuracy: 1.0\n",
      "Item 31 Accuracy: 0.0\n",
      "Item 32 Accuracy: 1.0\n",
      "Item 33 Accuracy: 0.0\n",
      "Item 34 Accuracy: 0.4\n",
      "Item 35 Accuracy: 0.0\n",
      "Item 36 Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(36):\n",
    "    print(f\"Item {i + 1} Accuracy:\",\n",
    "    (imagetext_df[imagetext_df['id'] == f\"{i:02d}\"]['correct'].sum())/5 # 5 attempts per item\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagetext_df.to_csv(\"nb4_gpt_rmet_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
